{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "15e80a54",
      "metadata": {
        "id": "15e80a54"
      },
      "source": [
        "# CLASSIFICATION-- CUSTOMER CHURN PREDICTION"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19c93acb",
      "metadata": {
        "id": "19c93acb"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "734ba730",
      "metadata": {
        "id": "734ba730"
      },
      "source": [
        "# Introduction (What is Customer Churn?)\n",
        "\n",
        "Customer churn is when customers or subscribers discontinue doing business with a firm or service.\n",
        "\n",
        "To be simple, it is when customers stops being your customer.\n",
        "\n",
        "Telco churn data includes information about a fictitious telecom company that provided home phone and Internet services to 7,043 California customers in the third quarter. Which customers have left, stayed, or signed up for their service shows?\n",
        "\n",
        "In this project, we aim to find the likelihood of a customer leaving the organization, the key indicators of churn as well as the retention strategies that can be implemented to avert this problem."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4ea7933",
      "metadata": {
        "id": "f4ea7933"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f3e8a153",
      "metadata": {
        "id": "f3e8a153"
      },
      "outputs": [],
      "source": [
        "# !pip install xgboost\n",
        "# !pip install -U imbalanced-learn\n",
        "# !pip install --upgrade scipy\n",
        "# !pip install threadpoolctl==3.1.0\n",
        "# !pip install category_encoders"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c54864f1",
      "metadata": {
        "id": "c54864f1"
      },
      "source": [
        "# Importation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "91b7e819",
      "metadata": {
        "id": "91b7e819"
      },
      "outputs": [],
      "source": [
        "# Data handling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import threadpoolctl\n",
        "# Vizualisation (Matplotlib, Plotly, Seaborn, etc. )\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# EDA (pandas-profiling, etc. )\n",
        "\n",
        "# Statistics\n",
        "from scipy import stats\n",
        "\n",
        "# Feature Processing (Scikit-learn processing, etc. )\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import Counter\n",
        "\n",
        "# balance data\n",
        "from imblearn import under_sampling, over_sampling\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Machine Learning (Scikit-learn Estimators, Catboost, LightGBM, etc. )\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, fbeta_score, roc_auc_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier, plot_importance\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Hyperparameters Fine-tuning (Scikit-learn hp search, cross-validation, etc. )\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Evaluations\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, RocCurveDisplay, roc_curve, auc\n",
        "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, cross_val_score\n",
        "from statistics import stdev\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Other packages\n",
        "import os, pickle\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Mounting Google Drive\n",
        "from google.colab import drive  # Import for accessing Google Drive\n",
        "\n",
        "# Unzipping files\n",
        "import zipfile  # Import for extracting zip files"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f21642a",
      "metadata": {
        "id": "7f21642a"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2abc3f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2abc3f0",
        "outputId": "300d2beb-3c30-4994-e106-3255728a5034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Get the file path from Google Drive\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/datasets/Fraud.zip'\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "    # Find the CSV files in the zip folder\n",
        "    file_path = zip_ref.extract('Fraud.csv', '/content/')\n",
        "\n",
        "# Read the csv file from the url\n",
        "data = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b86aff73",
      "metadata": {
        "id": "b86aff73"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c24c5674",
      "metadata": {
        "id": "c24c5674"
      },
      "source": [
        "## Hypothesis\n",
        "\n",
        "H0: The sample has a Gaussian distribution in the numerical feautures.\n",
        "\n",
        "H1: The sample does not have a Gaussian distribution in the numerical feautures."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebe4271a",
      "metadata": {
        "id": "ebe4271a"
      },
      "source": [
        "## Questions\n",
        "\n",
        "1. Does longer tenure increase churn?\n",
        "2. Is there any pattern in Customer Churn based on gender?\n",
        "3. Which type of contract keeps more customers?\n",
        "4. What's the most profitable Internetservice type?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "213daf05",
      "metadata": {
        "id": "213daf05"
      },
      "source": [
        "## Issues with the data\n",
        "\n",
        "1. Some of the columns are irrelevant.\n",
        "2. some of the columns are not in their respective data types.\n",
        "3. The data values in the column payments method needs is not good for readability.\n",
        "4. The data has missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "597b01e9",
      "metadata": {
        "id": "597b01e9"
      },
      "source": [
        "## How I Intend to Solve Them\n",
        "\n",
        "1. Drop irrelevant columns\n",
        "2. Replace the correct data types in their respective columns\n",
        "3. Rename the data values for better readability.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f96ebc8e",
      "metadata": {
        "id": "f96ebc8e"
      },
      "source": [
        "Rename the columns for better readability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "726070f5",
      "metadata": {
        "id": "726070f5"
      },
      "outputs": [],
      "source": [
        "data.rename(columns={\n",
        "    'step': 'time_step',\n",
        "    'type': 'trans_type',\n",
        "    'amount': 'trans_amt',\n",
        "    'nameOrig': 'cust_orig',\n",
        "    'oldbalanceOrg': 'old_orig_bal',\n",
        "    'newbalanceOrig': 'new_orig_bal',\n",
        "    'nameDest': 'cust_dest',\n",
        "    'oldbalanceDest': 'old_dest_bal',\n",
        "    'newbalanceDest': 'new_dest_bal'\n",
        "}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7e2c061",
      "metadata": {
        "id": "d7e2c061"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f37ddecf",
      "metadata": {
        "id": "f37ddecf"
      },
      "outputs": [],
      "source": [
        "data['isMerchant'] = data['cust_dest'].apply(lambda x: 1 if x.startswith('M') else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9db9164",
      "metadata": {
        "id": "a9db9164"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcbc0397",
      "metadata": {
        "id": "dcbc0397"
      },
      "outputs": [],
      "source": [
        "# summary of the dataframe\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b73bfbad",
      "metadata": {
        "id": "b73bfbad"
      },
      "outputs": [],
      "source": [
        "for col in data.columns:\n",
        "    if data[col].dtype == 'object':\n",
        "        print(col, data[col].nunique())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b74db7f",
      "metadata": {
        "id": "4b74db7f"
      },
      "source": [
        "cust_orig and cust_dest are unique for each transaction, so we can drop them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f67821be",
      "metadata": {
        "id": "f67821be"
      },
      "outputs": [],
      "source": [
        "data.drop(columns=['cust_orig', 'cust_dest'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b89e8bc0",
      "metadata": {
        "id": "b89e8bc0"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69d82642",
      "metadata": {
        "id": "69d82642"
      },
      "source": [
        "check for outliers only in the columns that shouldn't have outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cc50fed",
      "metadata": {
        "id": "1cc50fed"
      },
      "outputs": [],
      "source": [
        "# Check of outliers by applying the IQR method checking\n",
        "df = data.drop(['trans_type', 'time_step', 'isFraud', 'isFlaggedFraud', 'isMerchant'], axis=1)\n",
        "\n",
        "Q1 = df.quantile(0.25)\n",
        "Q3 = df.quantile(0.75)\n",
        "IQR = Q3-Q1\n",
        "IQR\n",
        "((df < (Q1-1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edd3d904",
      "metadata": {
        "id": "edd3d904"
      },
      "source": [
        "The results above showed there are outliers, but these outliers are probably because of fraudulent transactions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the boxplot\n",
        "df.boxplot()\n",
        "\n",
        "# Rotate x-axis labels by 45 degrees\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lu8f1kX3kctg"
      },
      "id": "lu8f1kX3kctg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Check if outliers still exist in the columns\n",
        "# outliers_exist = False\n",
        "\n",
        "# for col in df.columns.tolist():\n",
        "#     # Calculate the first and third quartiles (Q1 and Q3)\n",
        "#     Q1 = df[col].quantile(0.25)\n",
        "#     Q3 = df[col].quantile(0.75)\n",
        "\n",
        "#     # Calculate the interquartile range (IQR)\n",
        "#     IQR = Q3 - Q1\n",
        "\n",
        "#     # Define the lower and upper bounds for outliers\n",
        "#     lower_bound = Q1 - 1.5 * IQR\n",
        "#     upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "#     # Modify the values in the col to be within the range\n",
        "#     df[col] = df[col].clip(lower_bound, upper_bound)\n",
        "\n",
        "#     # Check if outliers exist in the col\n",
        "#     if (df[col] < lower_bound).any() or (df[col] > upper_bound).any():\n",
        "#         outliers_exist = True\n",
        "#         print(f\"Outliers still exist in '{col}'.\")"
      ],
      "metadata": {
        "id": "k-ppJBDSkgsX"
      },
      "id": "k-ppJBDSkgsX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the boxplot\n",
        "df.boxplot()\n",
        "\n",
        "# Rotate x-axis labels by 45 degrees\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CjaHKuK0nNe3"
      },
      "id": "CjaHKuK0nNe3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "682e269d",
      "metadata": {
        "id": "682e269d"
      },
      "source": [
        "## Bivariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b7481a1",
      "metadata": {
        "id": "7b7481a1"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize= (10,8))\n",
        "\n",
        "sns.countplot(data = data,\n",
        "              x = 'trans_type',\n",
        "              hue = 'isFraud')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a006d2d",
      "metadata": {
        "id": "5a006d2d"
      },
      "source": [
        "let's see for other categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fc373d8",
      "metadata": {
        "id": "7fc373d8"
      },
      "outputs": [],
      "source": [
        "# Setup figure\n",
        "cols = 2\n",
        "rows = 1\n",
        "fig = plt.figure(figsize= (10,8))\n",
        "\n",
        "# Plotting\n",
        "for i, col in enumerate(['isMerchant', 'isFlaggedFraud']):\n",
        "    ax=fig.add_subplot(rows, cols, i+1)\n",
        "    sns.countplot(x=data[col], hue='isFraud', data=data, ax=ax)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3097012b",
      "metadata": {
        "id": "3097012b"
      },
      "outputs": [],
      "source": [
        "# Apply logarithmic transformation to 'trans_amt' to handle skewness\n",
        "df = data\n",
        "df['log_trans_amt'] = np.log1p(df['trans_amt'])  # Using log1p to avoid log(0)\n",
        "\n",
        "# Create a plot with the transformed data\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.histplot(data=df, x='log_trans_amt', hue='isFraud', multiple='stack', alpha=0.5)\n",
        "plt.xlabel('Log of Transaction Amount')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Transaction Amounts by Fraud Status')\n",
        "plt.show()\n",
        "data.drop('log_trans_amt', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "p3hakBm9lzr8"
      },
      "id": "p3hakBm9lzr8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d836c386",
      "metadata": {
        "id": "d836c386"
      },
      "source": [
        "## Multivariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50832129",
      "metadata": {
        "id": "50832129"
      },
      "outputs": [],
      "source": [
        "numeric = [col for col in data.columns if data[col].dtype in ['int64', 'float64']]\n",
        "numeric.remove('isFraud')\n",
        "categoric = [col for col in data.columns if data[col].dtype == 'object']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29609156",
      "metadata": {
        "id": "29609156"
      },
      "source": [
        "It seems that white blood cell count and Alanine Aminotransferase (U/L)\n",
        "have little or no effect on disease possibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f3b740e",
      "metadata": {
        "id": "0f3b740e"
      },
      "outputs": [],
      "source": [
        "# correlation heatmap df\n",
        "correlation = data[numeric].corr()\n",
        "sns.heatmap(correlation, annot=True, fmt='.2f')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dbd6422",
      "metadata": {
        "id": "3dbd6422"
      },
      "outputs": [],
      "source": [
        "# correlation heatmap df\n",
        "correlation = data[numeric].corr()\n",
        "\n",
        "# Get column pairs with correlation > 0.5\n",
        "high_corr_pairs = []\n",
        "for i in range(len(correlation.columns)):\n",
        "    for j in range(i+1, len(correlation.columns)):\n",
        "        if abs(correlation.iloc[i, j]) > 0.5:\n",
        "            high_corr_pairs.append((correlation.columns[i], correlation.columns[j], correlation.iloc[i, j]))\n",
        "\n",
        "# Check if there are high correlation pairs\n",
        "if high_corr_pairs:\n",
        "    # Print column pairs with correlation > 0.5 and their correlation values\n",
        "    for pair in high_corr_pairs:\n",
        "        print(pair[0], \"-\", pair[1], \"Correlation:\", pair[2])\n",
        "else:\n",
        "    print(\"No high correlation columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7baf205f",
      "metadata": {
        "id": "7baf205f"
      },
      "source": [
        "these variables have a very high correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28a2f1d7",
      "metadata": {
        "id": "28a2f1d7"
      },
      "outputs": [],
      "source": [
        "# so we will drop one from each pair\n",
        "data.drop(columns=['old_orig_bal', 'old_dest_bal'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ffe32f8",
      "metadata": {
        "id": "1ffe32f8"
      },
      "outputs": [],
      "source": [
        "numeric = [col for col in data.columns if data[col].dtype in ['int64', 'float64']]\n",
        "numeric.remove('isFraud')\n",
        "\n",
        "color = ('#40DFEF', '#E78EA9')\n",
        "fig, ax = plt.subplots(2, 4, figsize=(20,8))\n",
        "\n",
        "# Flatten the axes array for easier indexing in the loop\n",
        "ax_flat = ax.flatten()\n",
        "\n",
        "for i, p in enumerate(numeric):\n",
        "    sns.boxplot(data=data, x='isFraud', y=p, ax=ax_flat[i], palette=color)\n",
        "    ax_flat[i].set_title(p)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5fb96ca",
      "metadata": {
        "id": "f5fb96ca"
      },
      "source": [
        "## Hypothesis validation\n",
        "\n",
        "## Statistical Normality Tests\n",
        "\n",
        "Normality tests are used to determine if a dataset is normally distributed about the mean value. it is assumed that during any measurement values will follow a normal distribution with an equal number of measurements above and below the mean value.\n",
        "\n",
        "on the other hand, Gaussian distribution is a continuous probability distribution with symmetrical sides around its center. Its mean, median and mode are equal.\n",
        "\n",
        "Popular normality tests - D’Agostino’s K^2, Shapiro-Wilk, Anderson-Darling .\n",
        "\n",
        "### D’Agostino’s K^2 Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eafe349b",
      "metadata": {
        "id": "eafe349b"
      },
      "outputs": [],
      "source": [
        "numeric = [col for col in data.columns if data[col].dtype in ['int64', 'float64']]\n",
        "for col in data[numeric]:\n",
        "    stat, p = stats.normaltest(data[col])\n",
        "    # print('Statistics=%.5f, p=%.3f' % (stat, p))\n",
        "\n",
        "    # interpret\n",
        "    alpha = 0.05\n",
        "    if p > alpha:\n",
        "        print(f'looks Gaussian (fail to reject H0) for this column: {col}')\n",
        "    else:\n",
        "        print(f'does not look Gaussian (reject H0) for this column: {col}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16fca39d",
      "metadata": {
        "id": "16fca39d"
      },
      "source": [
        "# Feature Processing & Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcdac66c",
      "metadata": {
        "id": "bcdac66c"
      },
      "source": [
        "## Drop Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eff2a874",
      "metadata": {
        "id": "eff2a874"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4de55688",
      "metadata": {
        "id": "4de55688"
      },
      "outputs": [],
      "source": [
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8790bea1",
      "metadata": {
        "id": "8790bea1"
      },
      "source": [
        "let's have a closer look at the duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7774c081",
      "metadata": {
        "id": "7774c081"
      },
      "outputs": [],
      "source": [
        "data['trans_type'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8ab7292",
      "metadata": {
        "id": "b8ab7292"
      },
      "outputs": [],
      "source": [
        "dup = data.loc[data.duplicated(),:]\n",
        "dup.head(22)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ef41a17",
      "metadata": {
        "id": "8ef41a17"
      },
      "source": [
        "these transactions look fraudulent,\n",
        "\n",
        "money was payed, but there is no trace of it in either sending or receiving accounts\n",
        "\n",
        "so we'll leave them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30lv4FTDuMpq"
      },
      "source": [
        "those do not look like duplicates, so we'll ignore"
      ],
      "id": "30lv4FTDuMpq"
    },
    {
      "cell_type": "markdown",
      "id": "214c2134",
      "metadata": {
        "id": "214c2134"
      },
      "source": [
        "## Creating new features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f12d2ebb",
      "metadata": {
        "id": "f12d2ebb"
      },
      "source": [
        "Most features turned out to have no effect\n",
        "on the performance of our best performing model\n",
        "\n",
        "so we will drop those features as they will not affect our f2 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f40f8395",
      "metadata": {
        "id": "f40f8395"
      },
      "outputs": [],
      "source": [
        "# columns_to_keep = [\n",
        "#     'Mean Corpuscular Hemoglobin (pg)',\n",
        "#     'Mean Corpuscular Volume (fL)',\n",
        "#     'Hematocrit (%)',\n",
        "#     'White Blood Cell Count (10^3/µL)',\n",
        "#     'Cholesterol Level (mg/dL)',\n",
        "#     'Platelet Count (10^9/L)',\n",
        "#     'White Blood Cell Count (10^3/µL)',\n",
        "#     'Glucose',\n",
        "#     'Disease'\n",
        "# ]\n",
        "\n",
        "# columns_to_drop = [col for col in data.columns if col not in columns_to_keep]\n",
        "# data.drop(columns=columns_to_drop, inplace=True, axis=1)\n",
        "# test.drop(columns=columns_to_drop, inplace=True, axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c25b640",
      "metadata": {
        "id": "6c25b640"
      },
      "source": [
        "## Impute Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c0f4abd",
      "metadata": {
        "id": "9c0f4abd"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10ce28b3",
      "metadata": {
        "id": "10ce28b3"
      },
      "outputs": [],
      "source": [
        "# Drop the missing rows\n",
        "# data = data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2baed49f",
      "metadata": {
        "id": "2baed49f"
      },
      "outputs": [],
      "source": [
        "df = data\n",
        "X = df.drop('isFraud', axis=1)\n",
        "y = df['isFraud']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "749f6179",
      "metadata": {
        "id": "749f6179"
      },
      "source": [
        "## Data Imbalance Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d905e3c",
      "metadata": {
        "id": "8d905e3c"
      },
      "outputs": [],
      "source": [
        "#Defining colors for the plots\n",
        "palette = ['#008080','#FF6347', '#E50000', '#D2691E']\n",
        "palette2 = ['#FF6347', '#008080', '#E50000', '#D2691E']\n",
        "\n",
        "l1 = list(data['isFraud'].value_counts())\n",
        "pie_values = [l1[0] / sum(l1) * 100, l1[1] / sum(l1) * 100]\n",
        "\n",
        "fig = plt.subplots(nrows = 1,ncols = 2,figsize = (20,7))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.pie(pie_values,labels = ['No Fraud','isFraud'],\n",
        "        autopct = '%1.2f%%',\n",
        "        explode = (0.1,0),\n",
        "        colors = palette,\n",
        "        wedgeprops = {'edgecolor': 'black','linewidth': 1, 'antialiased' : True})\n",
        "plt.title('isFraud and No Fraud %');\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "ax = sns.countplot(data = data,\n",
        "                   x='isFraud',\n",
        "                   palette = palette,\n",
        "                   edgecolor = 'black')\n",
        "for i in ax.containers:\n",
        "    ax.bar_label(i,)\n",
        "ax.set_xticklabels(['No Fraud','isFraud'])\n",
        "\n",
        "plt.title('isFraud and No Fraud')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99d79363",
      "metadata": {
        "id": "99d79363"
      },
      "source": [
        "Dataset is imbalanced.\n",
        "\n",
        "This means that a blind guess (on \"No Fraud\") would give us accuracy of 99%\n",
        "\n",
        "Therefore, we can't use Accuracy Score to choose our model\n",
        "\n",
        "what to do to solve this issue:\n",
        "\n",
        "1. We could use stratified splitting during train-test split (split the dataset in a way that preserves the same proportions of examples in each class.)\n",
        "2. We could be extra careful when dealing with outliers (we can delete meaningull information).\n",
        "3. Resampling Techniques — Oversample minority class or Undersample majority class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "507a4a64",
      "metadata": {
        "id": "507a4a64"
      },
      "outputs": [],
      "source": [
        "#Oversampling the minority class (the churn customers)\n",
        "ros = RandomOverSampler(random_state=0)\n",
        "X_new,y_new= ros.fit_resample(X, y)\n",
        "# X_new,y_new= X, y\n",
        "\n",
        "print(\"After Random Over Sampling Of Minor Class Total Samples are :\", len(y_new))\n",
        "print('Original dataset shape {}'.format(Counter(y)))\n",
        "print('Resampled dataset shape {}'.format(Counter(y_new)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c00a094",
      "metadata": {
        "id": "3c00a094"
      },
      "source": [
        "Now our data is balanced"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e154be43",
      "metadata": {
        "id": "e154be43"
      },
      "source": [
        "# Dataset Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c135237d",
      "metadata": {
        "id": "c135237d"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size = 0.20, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9adedbf5",
      "metadata": {
        "id": "9adedbf5"
      },
      "outputs": [],
      "source": [
        "X_train.shape, X_test.shape , y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7179b097",
      "metadata": {
        "id": "7179b097"
      },
      "source": [
        "# Features Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b317520d",
      "metadata": {
        "id": "b317520d"
      },
      "outputs": [],
      "source": [
        "numeric = [col for col in data.columns if data[col].dtype in ['int64', 'float64']]\n",
        "numeric.remove('isFraud')\n",
        "print(\"numeric_cols:\", numeric)\n",
        "print(\"categoric_cols:\", categoric)\n",
        "categoric = [col for col in data.columns if data[col].dtype == 'object']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f7b5b6e",
      "metadata": {
        "id": "8f7b5b6e"
      },
      "outputs": [],
      "source": [
        "# calling our encoder\n",
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False, drop=\"first\")\n",
        "# setting output to DataFrame\n",
        "encoder.set_output(transform=\"pandas\")\n",
        "# encoding our data\n",
        "X_catEncoded_train = encoder.fit_transform(X_train[categoric])\n",
        "X_catEncoded_test = encoder.transform(X_test[categoric]) # encoding our test data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e31fb85",
      "metadata": {
        "id": "3e31fb85"
      },
      "source": [
        "# Features Scaling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a04f761f",
      "metadata": {
        "id": "a04f761f"
      },
      "outputs": [],
      "source": [
        "Scaler = StandardScaler().fit(X_train[numeric]).set_output(transform=\"pandas\")\n",
        "\n",
        "X_numScaled_train = Scaler.transform(X_train[numeric])\n",
        "X_numScaled_test = Scaler.transform(X_test[numeric])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "216737b2",
      "metadata": {
        "id": "216737b2"
      },
      "outputs": [],
      "source": [
        "X_train = pd.concat([X_numScaled_train, X_catEncoded_train], axis=1)\n",
        "X_test = pd.concat([X_numScaled_test, X_catEncoded_test], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65fbefef",
      "metadata": {
        "id": "65fbefef"
      },
      "source": [
        "# Machine Learning Modeling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7825e6ca",
      "metadata": {
        "id": "7825e6ca"
      },
      "source": [
        "## 1.  Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e09d87c9",
      "metadata": {
        "id": "e09d87c9"
      },
      "source": [
        "### Create the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c16aab19",
      "metadata": {
        "id": "c16aab19"
      },
      "outputs": [],
      "source": [
        "model= LogisticRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff2e829a",
      "metadata": {
        "id": "ff2e829a"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f75a90b",
      "metadata": {
        "id": "2f75a90b"
      },
      "outputs": [],
      "source": [
        "model=model.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82707b0a",
      "metadata": {
        "id": "82707b0a"
      },
      "source": [
        "###  Predict on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "473c43df",
      "metadata": {
        "id": "473c43df"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(X_test)\n",
        "prob = model.predict_proba(X_test)[:,1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc806a2a",
      "metadata": {
        "id": "dc806a2a"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "914a2976",
      "metadata": {
        "id": "914a2976"
      },
      "outputs": [],
      "source": [
        "r_lgt= recall_score(y_test, pred)\n",
        "print(\"recall_score : \", r_lgt)\n",
        "\n",
        "p_lgt= precision_score(y_test, pred)\n",
        "print(\"precision_score :\",p_lgt)\n",
        "\n",
        "f1_lgt= f1_score(y_test, pred)\n",
        "print(\"f1_score :\", f1_lgt)\n",
        "\n",
        "f2_lgt = fbeta_score(y_test, pred, beta=2, average='binary')\n",
        "print(\"f2_score :\", f2_lgt)\n",
        "\n",
        "A_lgt= accuracy_score(pred, y_test)\n",
        "print(\"accuracy_score :\",A_lgt)\n",
        "\n",
        "acu_lgt = roc_auc_score(pred, y_test)\n",
        "print(\"ROC_AUC Score:\",acu_lgt)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "899a2476",
      "metadata": {
        "id": "899a2476"
      },
      "outputs": [],
      "source": [
        "# plot the model evaluation\n",
        "fpr, tpr, _ = roc_curve(y_test, prob)\n",
        "fig, ax = plt.subplots(figsize=(10,7))\n",
        "plt.title('Logistic Regression ROC curve')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.plot(fpr,tpr)\n",
        "plt.plot((0,1), linestyle=\"--\",color='black')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55006580",
      "metadata": {
        "id": "55006580"
      },
      "source": [
        "## 3. XGBoost Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74beedfa",
      "metadata": {
        "id": "74beedfa"
      },
      "source": [
        "### Create the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ff6b746",
      "metadata": {
        "id": "8ff6b746"
      },
      "outputs": [],
      "source": [
        "XG_model= XGBClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a776eb2",
      "metadata": {
        "id": "2a776eb2"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e3400b1",
      "metadata": {
        "id": "5e3400b1"
      },
      "outputs": [],
      "source": [
        "XG_model= XG_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0763132",
      "metadata": {
        "id": "c0763132"
      },
      "source": [
        "### Predict on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52e61bdc",
      "metadata": {
        "id": "52e61bdc"
      },
      "outputs": [],
      "source": [
        "XG_pred = XG_model.predict(X_test)\n",
        "XG_prob = XG_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de6b728d",
      "metadata": {
        "id": "de6b728d"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a88758c3",
      "metadata": {
        "id": "a88758c3"
      },
      "outputs": [],
      "source": [
        "r_XG= recall_score(y_test, XG_pred)\n",
        "print(\"recall_score : \", r_XG)\n",
        "\n",
        "p_XG= precision_score(y_test, XG_pred)\n",
        "print(\"precision_score :\",p_XG)\n",
        "\n",
        "f1_XG= f1_score(y_test, XG_pred)\n",
        "print(\"f1_score :\", f1_XG)\n",
        "\n",
        "f2_XG = fbeta_score(y_test, XG_pred, beta=2, average='binary')\n",
        "print(\"f2_score :\", f2_XG)\n",
        "\n",
        "\n",
        "A_XG= accuracy_score( y_test, XG_pred)\n",
        "print(\"accuracy_score :\",A_XG)\n",
        "\n",
        "acu_XG = roc_auc_score(XG_pred, y_test)\n",
        "print(\"ROC_AUC Score:\",acu_XG)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92b3e2c8",
      "metadata": {
        "id": "92b3e2c8"
      },
      "outputs": [],
      "source": [
        "#  plot the model evaluation\n",
        "fpr, tpr, _ = roc_curve(y_test, XG_prob)\n",
        "fig, ax = plt.subplots(figsize=(10,7))\n",
        "plt.title('XGBoost ROC curve')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.plot(fpr,tpr)\n",
        "plt.plot((0,1), linestyle=\"--\",color='black')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "007fd0a2",
      "metadata": {
        "id": "007fd0a2"
      },
      "source": [
        "##  6. DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "351c86b0",
      "metadata": {
        "id": "351c86b0"
      },
      "source": [
        "### Create the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57c57da1",
      "metadata": {
        "id": "57c57da1"
      },
      "outputs": [],
      "source": [
        "dtmodel = DecisionTreeClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f325e42",
      "metadata": {
        "id": "7f325e42"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1dd314a",
      "metadata": {
        "id": "a1dd314a"
      },
      "outputs": [],
      "source": [
        "dtmodel = dtmodel.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "561524af",
      "metadata": {
        "id": "561524af"
      },
      "source": [
        "### Predict on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13171444",
      "metadata": {
        "id": "13171444"
      },
      "outputs": [],
      "source": [
        "dt_pred = dtmodel.predict(X_test)\n",
        "dt_prob = dtmodel.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3918c978",
      "metadata": {
        "id": "3918c978"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c818cd3",
      "metadata": {
        "id": "7c818cd3"
      },
      "outputs": [],
      "source": [
        "r_dt= recall_score(y_test, dt_pred)\n",
        "print(\"recall_score : \", r_dt)\n",
        "\n",
        "p_dt= precision_score(y_test, dt_pred)\n",
        "print(\"precision_score :\",p_dt)\n",
        "\n",
        "f1_dt= f1_score(y_test, dt_pred)\n",
        "print(\"f1_score :\", f1_dt)\n",
        "\n",
        "f2_dt = fbeta_score(y_test, dt_pred, beta=2, average='binary')\n",
        "print(\"f2_score :\", f2_dt)\n",
        "\n",
        "\n",
        "A_dt= accuracy_score( y_test, dt_pred)\n",
        "print(\"accuracy_score :\", A_dt)\n",
        "\n",
        "acu_dt = roc_auc_score(dt_pred, y_test)\n",
        "print(\"ROC_AUC Score:\",acu_dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c286dfb6",
      "metadata": {
        "id": "c286dfb6"
      },
      "source": [
        "# Models comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d760629",
      "metadata": {
        "id": "5d760629"
      },
      "source": [
        "False Negatives:\n",
        "\n",
        "False negatives occur when the model incorrectly predicts that a patient does not have the disease when, in reality, they do.\n",
        "The consequence of a false negative is that the patient may not receive necessary treatment or intervention, potentially leading to undetected or untreated health issues. This can result in the progression of the disease, worsening health outcomes, and possibly even life-threatening situations if the disease is serious.\n",
        "\n",
        "Given that false negatives are more costly in this medical diagnosis classification project, and I've balanced the classes using Random Over Sampler, it's advisable to prioritize metrics that focus on minimizing false negatives.\n",
        "\n",
        "In this context, the most appropriate metric to use would be recall or the F2 score. Both of these metrics emphasize the minimization of false negatives, making them suitable for scenarios where the cost of missing positive cases (i.e., false negatives) is high."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4906e4f5",
      "metadata": {
        "id": "4906e4f5"
      },
      "outputs": [],
      "source": [
        "compare_models = ['Logistic Regression', 'XGBClassifier', 'DecisionTreeClassifier']\n",
        "\n",
        "data = {\n",
        "    'Accuracy': [A_lgt, A_XG, A_dt],\n",
        "    'Recall': [r_lgt, r_XG, r_dt],\n",
        "    'Precision': [p_lgt, p_XG, p_dt],\n",
        "    'f1_score': [f1_lgt, f1_XG, f1_dt],\n",
        "    'f2_score': [f2_lgt, f2_XG, f2_dt],\n",
        "    'ROC_AUC': [acu_lgt, acu_XG, acu_dt],\n",
        "    'Description': ['', 'best model', '']\n",
        "}\n",
        "result=pd.DataFrame(data=data, index=compare_models)\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81ca799a",
      "metadata": {
        "id": "81ca799a"
      },
      "source": [
        "In a fraud detection project, it is generally more important to prioritize false negatives over false positives. This is because false negatives mean that fraudulent transactions go undetected, leading to potential financial losses and other negative consequences. False positives, while inconvenient, do not result in direct financial loss and can be managed with additional verification steps.\n",
        "\n",
        "Given this context, the best metrics to focus on are Recall and f2_score. Recall measures the ability to identify actual fraud cases correctly (minimizing false negatives), while the f2_score places more emphasis on recall compared to precision."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7cc7d96",
      "metadata": {
        "id": "d7cc7d96"
      },
      "source": [
        "\n",
        "Based on the above metrics, **XGBClassifier is the best model** for this fraud detection project as it has the highest recall (0.870370) and a high f2_score (0.886346), indicating it is effective in detecting fraudulent transactions while minimizing false negatives."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4beba0c",
      "metadata": {
        "id": "e4beba0c"
      },
      "source": [
        "In the context of fraud detection, ROC_AUC is important because it gives a holistic view of the model's performance across all classification thresholds.\n",
        "\n",
        "Based on the ROC_AUC values and previously discussed metrics (recall and f2_score), XGBClassifier stands out as the best model for this fraud detection project with the highest ROC_AUC (0.978208)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c229ba53",
      "metadata": {
        "id": "c229ba53"
      },
      "source": [
        "# k-Fold cross validation\n",
        "\n",
        "## XGBoost Classifier (Best Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad86389f",
      "metadata": {
        "id": "ad86389f"
      },
      "outputs": [],
      "source": [
        "xgb_dt = KFold(n_splits = 5,shuffle=True)\n",
        "# Define custom F2 scorer\n",
        "f2_scorer = make_scorer(fbeta_score, beta=2)\n",
        "\n",
        "score = cross_val_score(XG_model, X_train, y_train, cv=xgb_dt, scoring=f2_scorer, error_score=\"raise\")\n",
        "xgb_cv_score = score.mean()\n",
        "xgb_cv_stdev = stdev(score)\n",
        "print('Cross Validation f2 scores are: {}'.format(score))\n",
        "print('Average Cross Validation f2 score: ', xgb_cv_score)\n",
        "print('Cross Validation f2 standard deviation: ', xgb_cv_stdev)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa1f2899",
      "metadata": {
        "id": "aa1f2899"
      },
      "source": [
        "# Model Improvement\n",
        "\n",
        "# Hyperparameters tuning\n",
        "\n",
        "## DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db5c2619",
      "metadata": {
        "id": "db5c2619"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid for XGBoost\n",
        "param_grid_xgb = {\n",
        "    'max_depth': [3, 5, 7, 10],  # Maximum depth of a tree\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],  # Step size shrinkage used in update to prevent overfitting\n",
        "    'n_estimators': [100, 200, 300],  # Number of boosting rounds\n",
        "    'gamma': [0, 0.1, 0.3, 0.5],  # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
        "    'colsample_bytree': [0.3, 0.5, 0.7, 1.0],  # Subsample ratio of columns when constructing each tree\n",
        "    'subsample': [0.7, 0.8, 0.9, 1.0],  # Subsample ratio of the training instances\n",
        "    'reg_alpha': [0, 0.1, 0.5, 1],  # L1 regularization term on weights\n",
        "    'reg_lambda': [0.1, 1, 10]  # L2 regularization term on weights\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5d4409d",
      "metadata": {
        "id": "d5d4409d"
      },
      "outputs": [],
      "source": [
        "# make GridSearchCV object\n",
        "xgb_Grid = GridSearchCV(estimator = XG_model,\n",
        "                       param_grid = param_grid_xgb,\n",
        "                       cv = 4,\n",
        "                       verbose = 2 ,\n",
        "                       n_jobs = -1,\n",
        "                       scoring=f2_scorer,\n",
        "                       refit=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60619d80",
      "metadata": {
        "id": "60619d80"
      },
      "outputs": [],
      "source": [
        "# Fit the GridSearchCV object to the data\n",
        "xgb_Grid.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "595c03f2",
      "metadata": {
        "id": "595c03f2"
      },
      "outputs": [],
      "source": [
        "# Get the best estimator and its score\n",
        "xgb_tuned = xgb_Grid.best_estimator_\n",
        "xgb_Grid.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fc018d1",
      "metadata": {
        "id": "9fc018d1"
      },
      "outputs": [],
      "source": [
        "# Use the best estimator for predictions\n",
        "y_pred_grid = xgb_tuned.predict(X_test)\n",
        "f2_xgb = fbeta_score(y_test, y_pred_grid, beta=2, average='binary')\n",
        "print(\"f2_score :\", f2_xgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98323e4d",
      "metadata": {
        "id": "98323e4d"
      },
      "outputs": [],
      "source": [
        "# with open('model.pkl', 'wb') as f:\n",
        "#     pickle.dump(xgb_tuned, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a5c85cc",
      "metadata": {
        "id": "3a5c85cc"
      },
      "source": [
        "# Using Confusion Matrix For Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b88de2ac",
      "metadata": {
        "id": "b88de2ac"
      },
      "source": [
        "# DecisionTree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8c77928",
      "metadata": {
        "id": "c8c77928"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,7))\n",
        "y_pred_xgb = xgb_Grid.best_estimator_.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_xgb, labels=xgb_Grid.best_estimator_.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                             display_labels=xgb_Grid.best_estimator_.classes_)\n",
        "disp.plot(ax=ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cf9d718",
      "metadata": {
        "id": "4cf9d718"
      },
      "source": [
        "Based on confusion matrix:\n",
        "\n",
        "1. We successfully predicted 416 patients with no disease and 5 with disease\n",
        "2. There are 65 patients who are predicted to have disease when they actually won't\n",
        "3. There are 0 patients who are predicted to not have disease when they actually do"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21f70f4a",
      "metadata": {
        "id": "21f70f4a"
      },
      "source": [
        "# Feature Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "572f6f9c",
      "metadata": {
        "id": "572f6f9c"
      },
      "source": [
        "# DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46a4eab2",
      "metadata": {
        "id": "46a4eab2"
      },
      "outputs": [],
      "source": [
        "fimp = pd.Series(data=XG_model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
        "plt.figure(figsize=(17,13))\n",
        "plt.title(\"Feature importance\")\n",
        "ax = sns.barplot(y=fimp.index, x=fimp.values, palette=palette, orient='h')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22d463e7",
      "metadata": {
        "id": "22d463e7"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "Looking at model results, the best Precision on the test set is achieved by  RandomForest Classifier with 0.89 .\n",
        "\n",
        "Given the high imbalance of the data towards non-churners, it makes sense to compare F1 scores to get the model with the best\n",
        "\n",
        "score on jointly precision and recall. This would also be the  RandomForest Classifier with a F1 score of 0.90 .\n",
        "\n",
        "Given the scores of the best performing models, it can be observed that F1 scores are not much above 90%.\n",
        "\n",
        "Further optimization efforts should be carried out to achieve a higher scores and thereby increase prediction power for more\n",
        "\n",
        "business value.\n",
        "\n",
        "When we consider the Exploratory Data Analysis we did, it is clear that this company has some issue with their Month-to-month\n",
        "\n",
        "customers.\n",
        "\n",
        "What kind of incentives can this company offer to customers to get them to sign One-year or Two-year contracts?\n",
        "\n",
        "What adjustments can be made to Month-to-Month contracts that would be more favorable to customers, without taking away the\n",
        "\n",
        "appeal of a One-year or Two-year contract?\n",
        "\n",
        "For RandomForest Classifier, you can see TotalCharges has a positive influence on the data and some features like\n",
        "\n",
        "InternetService_fibreoptics,contract_one year and etc should be examine critically since it has negative impact on the target column.\n",
        "\n",
        " Recommendation and Request\n",
        "\n",
        "We should pay more attention to customers who meet the criteria below\n",
        "\n",
        "1. Contract: Month-to-month\n",
        "2. Tenure: Short tenure\n",
        "3. Internet service: Fiber optic\n",
        "4. Payment method: Electronic check"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "7679c2132d3f6ce38c9df14d554b39c06862b36a4e6689c81f9ae15bd0911d7d"
      }
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}